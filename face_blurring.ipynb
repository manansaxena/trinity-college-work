{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXodGDN3oNr4"
      },
      "outputs": [],
      "source": [
        "!mkdir videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36LnzWDk6swV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tXC_fz_JCpor"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['DSFDDetector', 'RetinaNetResNet50', 'RetinaNetMobileNetV1']\n"
          ]
        }
      ],
      "source": [
        "import face_detection\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(face_detection.available_detectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WS0XYH7LaQn"
      },
      "outputs": [],
      "source": [
        "def anonymize_face_pixelate(image, blocks=3):\n",
        "\t# divide the input image into NxN blocks\n",
        "\t(h, w) = image.shape[:2]\n",
        "\txSteps = np.linspace(0, w, blocks + 1, dtype=\"int\")\n",
        "\tySteps = np.linspace(0, h, blocks + 1, dtype=\"int\")\n",
        "\n",
        "\t# loop over the blocks in both the x and y direction\n",
        "\tfor i in range(1, len(ySteps)):\n",
        "\t\tfor j in range(1, len(xSteps)):\n",
        "\t\t\t# compute the starting and ending (x, y)-coordinates\n",
        "\t\t\t# for the current block\n",
        "\t\t\tstartX = xSteps[j - 1]\n",
        "\t\t\tstartY = ySteps[i - 1]\n",
        "\t\t\tendX = xSteps[j]\n",
        "\t\t\tendY = ySteps[i]\n",
        "\n",
        "\t\t\t# extract the ROI using NumPy array slicing, compute the\n",
        "\t\t\t# mean of the ROI, and then draw a rectangle with the\n",
        "\t\t\t# mean RGB values over the ROI in the original image\n",
        "\t\t\troi = image[startY:endY, startX:endX]\n",
        "\t\t\t(B, G, R) = [int(x) for x in cv2.mean(roi)[:3]]\n",
        "\t\t\tcv2.rectangle(image, (startX, startY), (endX, endY),\n",
        "\t\t\t\t(B, G, R), -1)\n",
        "\n",
        "\t# return the pixelated blurred image\n",
        "\treturn image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EstZraOoark"
      },
      "outputs": [],
      "source": [
        "video_folder = '/content/videos/'\n",
        "\n",
        "boxes = True \n",
        "\n",
        "filenames = []\n",
        "filepaths = []\n",
        "for i in sorted(os.listdir(video_folder)):\n",
        "    if i[-4:] == '.mp4':\n",
        "        filenames.append(i[:-4])\n",
        "        filepaths.append(video_folder+i)\n",
        "print(filenames,filepaths)\n",
        "\n",
        "output_filepaths = []\n",
        "for i in filenames:\n",
        "    if boxes is True:\n",
        "        output_filepaths.append(video_folder+i+'_boxes.avi')\n",
        "    else:\n",
        "        output_filepaths.append(video_folder+i+'_blurred.avi')\n",
        "print(output_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HqbkzOqE-Cr"
      },
      "outputs": [],
      "source": [
        "for i,video in enumerate(filepaths):\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    frame_width = int(cap.get(3)) \n",
        "    frame_height = int(cap.get(4)) \n",
        "    size = (frame_width, frame_height) \n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "    out = cv2.VideoWriter(output_filepaths[i],fourcc, 20.0, size)\n",
        "\n",
        "    detector = face_detection.build_detector(\n",
        "    \"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        detections = detector.detect(frame)\n",
        "        \n",
        "        for face in detections:\n",
        "            if face[4] > 0.5:\n",
        "                if boxes is True:\n",
        "                    cv2.rectangle(frame,(face[0],face[1]),(face[2],face[3]),(255.0,0),3)\n",
        "                else:\n",
        "                    roi = frame[int(face[1]):int(face[3]),int(face[0]):int(face[2])]\n",
        "                    roi = anonymize_face_pixelate(roi,blocks=4)\n",
        "                    frame[int(face[1]):int(face[3]),int(face[0]):int(face[2])] = roi\n",
        "                \n",
        "        out.write(frame)\n",
        "        \n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0M213G8JEZl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "face blurring.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
